{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnalisisDatos1.1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcKvz9N9cmWcArbGfmnCOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaDelCarmenHernandezDiaz/Extraccion-de-conocimientos-de-base-de-datos/blob/main/AnalisisDatos1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPvQu9jLtBho"
      },
      "source": [
        "# **Explore y analice datos con Python**\n",
        "\n",
        "`Intermedio`    `Científico de datos`    `Código de Visual Studio`\n",
        "\n",
        "![An image](https://docs.microsoft.com/learn/achievements/explore-and-analyze-data-with-python-social.png)\n",
        "\n",
        "La exploración y el análisis de datos son el núcleo de la ciencia de datos. Los científicos de datos requieren habilidades en lenguajes como Python para explorar, visualizar y manipular datos.\n",
        "\n",
        "\n",
        "### Objetivos de aprendizaje.\n",
        "\n",
        "> En este módulo, aprenderá:\n",
        "\n",
        "* Tareas comunes de exploración y análisis de datos.\n",
        "* Cómo usar paquetes de Python como NumPy, Pandas y Matplotlib para analizar datos.\n",
        "\n",
        "### Prerrequisitos.\n",
        "\n",
        "> En este módulo, aprenderá:\n",
        "\n",
        "* Conocimiento de matemáticas básicas.\n",
        "* Alguna experiencia programando en Python.\n",
        "\n",
        "### Temario.\n",
        "\n",
        "> Introduccion\n",
        "\n",
        "> Explore datos con NumPy y Pandas\n",
        "\n",
        "> Ejercicio: explorar datos con NumPy y Pandas\n",
        "\n",
        "> Visualizar datos\n",
        "\n",
        "> Ejercicio: visualizar datos con Matplotlib\n",
        "\n",
        "> Examinar datos del mundo real\n",
        "\n",
        "> Ejercicio: examinar datos del mundo real\n",
        "\n",
        "> Verificación de conocimientos\n",
        "\n",
        "> Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQC65yVKvlN3"
      },
      "source": [
        "# **Introducción.**\n",
        "\n",
        "Como era de esperar, el papel de un científico de datos implica principalmente explorar y analizar datos. Los resultados de un análisis pueden formar la base de un informe o un modelo de aprendizaje automático, pero todo comienza con los datos, siendo Python el lenguaje de programación más popular para los científicos de datos.\n",
        "\n",
        "Después de décadas de desarrollo de código abierto, Python proporciona una amplia funcionalidad con potentes bibliotecas estadísticas y numéricas:\n",
        "\n",
        "* NumPy y Pandas simplifican el análisis y la manipulación de datos\n",
        "* Matplotlib proporciona visualizaciones de datos atractivas\n",
        "* Scikit-learn ofrece un análisis de datos predictivo simple y efectivo\n",
        "* TensorFlow y PyTorch ofrecen capacidades de aprendizaje automático y aprendizaje profundo\n",
        "\n",
        "Por lo general, un proyecto de análisis de datos está diseñado para establecer conocimientos sobre un escenario particular o para probar una hipótesis.\n",
        "\n",
        "Por ejemplo, supongamos que un profesor universitario recopila datos de sus estudiantes, incluido el número de conferencias a las que asistieron, las horas dedicadas al estudio y la calificación final obtenida en el examen de fin de trimestre. El profesor podría analizar los datos para determinar si existe una relación entre la cantidad de estudios que realiza un alumno y la nota final que obtiene. El profesor podría usar los datos para probar la hipótesis de que solo los estudiantes que estudian durante un número mínimo de horas pueden esperar obtener una calificación aprobatoria.\n",
        "\n",
        "![An image](https://docs.microsoft.com/en-us/learn/modules/explore-analyze-data-with-python/media/student-grades.png)\n",
        "\n",
        "\n",
        "### Prerequisitos \n",
        "\n",
        "* Conocimiento de matemáticas básicas.\n",
        "* Alguna experiencia programando en Python\n",
        "\n",
        "### Objetivos de aprendizaje \n",
        "\n",
        "En este módulo, podrá:\n",
        "\n",
        "* Tareas comunes de exploración y análisis de datos.\n",
        "* Cómo usar paquetes de Python como NumPy, Pandas y Matplotlib para analizar datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvqpbKH3MrPT"
      },
      "source": [
        "# **Explore datos con NumPy y Pandas**\n",
        "\n",
        "Los científicos de datos pueden utilizar diversas herramientas y técnicas para explorar, visualizar y manipular datos. Una de las formas más comunes en las que los científicos de datos trabajan con datos es utilizar el lenguaje Python y algunos paquetes específicos para el procesamiento de datos.\n",
        "\n",
        "### ¿Qué es NumPy?\n",
        "\n",
        "NumPy es una biblioteca de Python que brinda una funcionalidad comparable a las herramientas matemáticas como MATLAB y R. Si bien NumPy simplifica significativamente la experiencia del usuario, también ofrece funciones matemáticas integrales.\n",
        "\n",
        "### ¿Qué es pandas?\n",
        "\n",
        "Pandas es una biblioteca de Python extremadamente popular para el análisis y la manipulación de datos. Pandas es como Excel para Python: proporciona una funcionalidad fácil de usar para tablas de datos.\n",
        "\n",
        "![An image](https://docs.microsoft.com/en-us/learn/modules/explore-analyze-data-with-python/media/2-pandas-df.png)\n",
        "\n",
        "### Explore los datos en un cuaderno de Jupyter\n",
        "\n",
        "Los cuadernos de Jupyter son una forma popular de ejecutar scripts básicos con su navegador web. Por lo general, estos cuadernos son una sola página web, dividida en secciones de texto y secciones de código que se ejecutan en el servidor en lugar de en su máquina local. Esto significa que puede comenzar rápidamente sin necesidad de instalar Python u otras herramientas.\n",
        "\n",
        "### Prueba de hipótesis\n",
        "\n",
        "La exploración y el análisis de datos suele ser un proceso iterativo , en el que el científico de datos toma una muestra de datos y realiza los siguientes tipos de tareas para analizarlos y probar hipótesis:\n",
        "\n",
        "* Limpiar datos para manejar errores, valores perdidos y otros problemas.\n",
        "* Aplicar técnicas estadísticas para comprender mejor los datos y cómo se puede esperar que la muestra represente la población de datos del mundo real, lo que permite una variación aleatoria.\n",
        "* Visualice los datos para determinar las relaciones entre las variables y, en el caso de un proyecto de aprendizaje automático, identifique las características que son potencialmente predictivas de la etiqueta.\n",
        "* Revise la hipótesis y repita el proceso.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqS4tT2Vi8o3"
      },
      "source": [
        "# Ejercicio: explorar datos con NumPy y Pandas\n",
        "\n",
        "# Explorando datos con Python\n",
        "Una parte importante del rol de un científico de datos es explorar, analizar y visualizar datos. Existe una amplia gama de herramientas y lenguajes de programación que pueden usar para hacer esto; y uno de los enfoques más populares es usar cuadernos de Jupyter (como este) y Python.\n",
        "\n",
        "Python es un lenguaje de programación flexible que se utiliza en una amplia gama de escenarios; desde aplicaciones web hasta programación de dispositivos. Es extremadamente popular en la comunidad de ciencia de datos y aprendizaje automático debido a los muchos paquetes que admite para el análisis y la visualización de datos.\n",
        "\n",
        "En este cuaderno, exploraremos algunos de estos paquetes y aplicaremos técnicas básicas para analizar datos. No se pretende que sea un ejercicio completo de programación de Python; o incluso una inmersión profunda en el análisis de datos. Más bien, está pensado como un curso acelerado sobre algunas de las formas comunes en las que los científicos de datos pueden usar Python para trabajar con datos.\n",
        "\n",
        "> **Nota**: Si nunca antes ha utilizado el entorno de Jupyter Notebooks, hay algunas cosas que debe tener en cuenta:\n",
        "* Los cuadernos están formados por células. Algunas celdas (como esta) contienen texto de rebajas, mientras que otras (como la que está debajo de esta) contienen código.\n",
        "* Puede ejecutar cada celda de código utilizando el botón **► Ejecutar**. el botón **► Ejecutar** aparecerá cuando pase el cursor sobre la celda.\n",
        "* La salida de cada celda de código se mostrará inmediatamente debajo de la celda.\n",
        "* Aunque las celdas de código se pueden ejecutar individualmente, algunas variables utilizadas en el código son globales para el portátil. Eso significa que debe ejecutar todas las celdas de código en orden. Puede haber dependencias entre las celdas de código, por lo que si omite una celda, es posible que las celdas siguientes no se ejecuten correctamente.\n",
        "\n",
        "## Explorando matrices de datos con NumPy\n",
        "\n",
        "Comencemos mirando algunos datos simples.\n",
        "\n",
        "Suponga que una universidad toma una muestra de las calificaciones de los estudiantes para una clase de ciencia de datos.\n",
        "\n",
        "Ejecute el código en la celda de abajo haciendo clic en el botón **► Ejecutar** para ver los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFS5bsO7ivgO"
      },
      "source": [
        "data = [50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM379JHljUjk"
      },
      "source": [
        "Los datos se han cargado en una estructura de lista de Python , que es un buen tipo de datos para la manipulación de datos en general, pero no está optimizado para el análisis numérico. Para ello, vamos a utilizar el NumPy paquete, que incluye los tipos de datos y funciones específicas para trabajar con Num fibras en Py Thon.\n",
        "\n",
        "Ejecute la celda a continuación para cargar los datos en una **matriz** NumPy ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmjTa0tHjYi0"
      },
      "source": [
        "import numpy as np\n",
        "grades = np.array(data)\n",
        "print(grades)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyobbEbGj_MS"
      },
      "source": [
        "En caso de que se esté preguntando acerca de las diferencias entre una lista y una matriz NumPy , comparemos cómo se comportan estos tipos de datos cuando los usamos en una expresión que los multiplica por 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RD54RiTkB2h"
      },
      "source": [
        "print (type(data),'x 2:', data * 2)\n",
        "print('---')\n",
        "print (type(grades),'x 2:', grades * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug_w0Ek4kJ7m"
      },
      "source": [
        "Tenga en cuenta que multiplicar una lista por 2 crea una nueva lista de dos veces la longitud con la secuencia original de elementos de la lista repetida. Al multiplicar una matriz NumPy, por otro lado, se realiza un cálculo por elementos en el que la matriz se comporta como un vector , por lo que terminamos con una matriz del mismo tamaño en la que cada elemento se ha multiplicado por 2.\n",
        "\n",
        "La conclusión clave de esto es que las matrices NumPy están diseñadas específicamente para admitir operaciones matemáticas en datos numéricos, lo que las hace más útiles para el análisis de datos que una lista genérica.\n",
        "\n",
        "Es posible que haya notado que el tipo de clase para la matriz numpy anterior es un numpy.ndarray . La nd indica que esta es una estructura que puede constar de múltiples dimensiones (puede tener n dimensiones). Nuestra instancia específica tiene una sola dimensión de calificaciones de los estudiantes.\n",
        "\n",
        "Ejecute la celda de abajo para ver la forma de la matriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuIZlteRkR8h"
      },
      "source": [
        "grades.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbD0uNwQkXl6"
      },
      "source": [
        "La forma confirma que esta matriz tiene una sola dimensión, que contiene 22 elementos (hay 22 grados en la lista original). Puede acceder a los elementos individuales de la matriz por su posición ordinal basada en cero. Consigamos el primer elemento (el que está en la posición 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS5rVzAcka1k"
      },
      "source": [
        "grades[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6q1OxWZkhMX"
      },
      "source": [
        "Muy bien, ahora que conoce el camino alrededor de una matriz NumPy, es hora de realizar un análisis de los datos de calificaciones.\n",
        "\n",
        "Puede aplicar agregaciones entre los elementos de la matriz, así que busquemos la calificación promedio simple (en otras palabras, el valor medio de la calificación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuDU0mHDkjNu"
      },
      "source": [
        "grades.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0O-a6jDkqA2"
      },
      "source": [
        "Entonces, la nota media es de alrededor de 50, más o menos en el medio del rango posible de 0 a 100.\n",
        "\n",
        "Agreguemos un segundo conjunto de datos para los mismos estudiantes, esta vez registrando el número típico de horas por semana que dedicaron a estudiar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcXX1rOPktbW"
      },
      "source": [
        "# Definir una variedad de horas de estudio.\n",
        "study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,12.0,12.5,12.0]\n",
        "# Cree una matriz 2D (una matriz de matrices)\n",
        "student_data = np.array([study_hours, grades])\n",
        "# Mostrar la matriz\n",
        "student_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Hv0t9GlBaU"
      },
      "source": [
        "Ahora los datos consisten en una matriz bidimensional, una matriz de matrices. Veamos su forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RLL0UThlGnv"
      },
      "source": [
        "# Mostrar forma de matriz 2D\n",
        "student_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3uXCZZjlL5z"
      },
      "source": [
        "La matriz student_data contiene dos elementos, cada uno de los cuales es una matriz que contiene 22 elementos.\n",
        "\n",
        "Para navegar por esta estructura, debe especificar la posición de cada elemento en la jerarquía. Entonces, para encontrar el primer valor en la primera matriz (que contiene los datos de las horas de estudio, puede usar el siguiente código.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK40jR_lP5N"
      },
      "source": [
        "# Muestre el primer elemento del primer elemento.\n",
        "student_data[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PbA5O2vlS7T"
      },
      "source": [
        "Ahora tiene una matriz multidimensional que contiene tanto el tiempo de estudio del estudiante como la información de calificaciones, que puede usar para comparar datos. Por ejemplo, ¿cómo se compara el tiempo medio de estudio con la nota media?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysj9JjWTlXIW"
      },
      "source": [
        "# Obtenga el valor medio de cada submatriz.\n",
        "avg_study = student_data[0].mean()\n",
        "avg_grade = student_data[1].mean()\n",
        "print('Average study hours: {:.2f}\\nAverage grade: {:.2f}'.format(avg_study, avg_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ksuMkOlc5x"
      },
      "source": [
        "### Explorando datos tabulares con Pandas.\n",
        "\n",
        "Si bien NumPy proporciona muchas de las funciones que necesita para trabajar con números, y específicamente matrices de valores numéricos; Cuando comienza a trabajar con tablas de datos bidimensionales, el paquete **Pandas** ofrece una estructura más conveniente para trabajar: el **DataFrame**.\n",
        "\n",
        "Ejecute la siguiente celda para importar la biblioteca Pandas y cree un DataFrame con tres columnas. La primera columna es una lista de los nombres de los estudiantes, y la segunda y tercera columnas son las matrices NumPy que contienen el tiempo de estudio y los datos de las calificaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmFc-vVMlf-c"
      },
      "source": [
        "import pandas as pd\n",
        "df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', 'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny','Jakeem','Helena','Ismat','Anila','Skye','Daniel','Aisha'],                            'StudyHours':student_data[0],\n",
        "'Grade':student_data[1]})\n",
        "\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSeJHwT_llnK"
      },
      "source": [
        "Tenga en cuenta que, además de las columnas que especificó, el DataFrame incluye un índice para identificar de forma única cada fila. Podríamos haber especificado el índice explícitamente y asignado cualquier tipo de valor apropiado (por ejemplo, una dirección de correo electrónico); pero como no especificamos un índice, se ha creado uno con un valor entero único para cada fila.\n",
        "\n",
        "### Encontrar y filtrar datos en un DataFrame\n",
        "\n",
        "Puede usar el método loc de DataFrame para recuperar datos para un valor de índice específico, como este."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0II-VRe0lq26"
      },
      "source": [
        "# Obtenga los datos para el valor de índice 5\n",
        "df_students.loc[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHFFfXbVlto2"
      },
      "source": [
        "También puede obtener los datos en un rango de valores de índice, como este:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9lpc3Yelwmw"
      },
      "source": [
        "# Obtenga las filas con valores de índice de 0 a 5\n",
        "df_students.loc[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHc9AAuflyuZ"
      },
      "source": [
        "Además de poder usar el método loc para buscar filas según el índice, puede usar el método iloc para buscar filas según su posición ordinal en el DataFrame (independientemente del índice):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY2SH2EAl5PP"
      },
      "source": [
        "# Obtener datos en las primeras cinco filas\n",
        "df_students.iloc[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRSir7nmma-R"
      },
      "source": [
        "Mire cuidadosamente los iloc[0:5]resultados y compárelos con los loc[0:5]resultados que obtuvo anteriormente. ¿Puedes ver la diferencia?\n",
        "\n",
        "El método loc devolvió filas con etiqueta de índice en la lista de valores de 0 a 5 , que incluye 0, 1, 2, 3, 4 y 5 (seis filas). Sin embargo, el método iloc devuelve las filas en las posiciones incluidas en el rango de 0 a 5, y dado que los rangos de números enteros no incluyen el valor del límite superior, esto incluye las posiciones 0, 1, 2, 3 y 4 (cinco filas) .\n",
        "\n",
        "iloc identifica valores de datos en un DataFrame por posición , que se extiende más allá de las filas a las columnas. Entonces, por ejemplo, puede usarlo para encontrar los valores de las columnas en las posiciones 1 y 2 en la fila 0, así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZlQ_tJnmaeX"
      },
      "source": [
        "df_students.iloc[0,[1,2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgZQanAmjEJ"
      },
      "source": [
        "Volvamos al método loc y veamos cómo funciona con columnas. Recuerde que loc se usa para ubicar elementos de datos basados en valores de índice en lugar de posiciones. En ausencia de una columna de índice explícita, las filas en nuestro marco de datos se indexan como valores enteros, pero las columnas se identifican por su nombre:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLlJNuD1mlJ2"
      },
      "source": [
        "df_students.loc[0,'Grade']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gN3ShVomn46"
      },
      "source": [
        "Aquí hay otro truco útil. Puede usar el método loc para buscar filas indexadas en función de una expresión de filtrado que haga referencia a columnas con nombre distintas del índice, como esta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrt4phEQmprT"
      },
      "source": [
        "df_students.loc[df_students['Name']=='Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcSZ2HBsmuKB"
      },
      "source": [
        "En realidad, no necesita usar explícitamente el método loc para hacer esto; simplemente puede aplicar una expresión de filtrado de DataFrame, como esta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEJPG1jsmxbH"
      },
      "source": [
        "df_students[df_students['Name']=='Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPoUOhGqm23E"
      },
      "source": [
        "Y en buena medida, puede lograr los mismos resultados utilizando el método de consulta de DataFrame , como este:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a53vnAa6m5rC"
      },
      "source": [
        "df_students.query('Name==\"Aisha\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGi7Tgh8m9gA"
      },
      "source": [
        "Los tres ejemplos anteriores subrayan una verdad ocasionalmente confusa sobre trabajar con Pandas. A menudo, hay varias formas de lograr los mismos resultados. Otro ejemplo de esto es la forma en que se refiere al nombre de una columna de DataFrame. Puede especificar el nombre de la columna como un valor de índice con nombre (como en los df_students['Name']ejemplos que hemos visto hasta ahora), o puede usar la columna como una propiedad del DataFrame, así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ703dxZnAxS"
      },
      "source": [
        "df_students[df_students.Name == 'Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkvLv-8BnDk9"
      },
      "source": [
        "### Cargando un DataFrame desde un archivo\n",
        "\n",
        "Construimos el DataFrame a partir de algunas matrices existentes. Sin embargo, en muchos escenarios del mundo real, los datos se cargan desde fuentes como archivos. Reemplacemos el DataFrame de calificaciones de los estudiantes con el contenido de un archivo de texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inv4ZT8inHeb"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
        "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
        "df_students.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gL94q37nMoh"
      },
      "source": [
        "El método read_csv de DataFrame se usa para cargar datos desde archivos de texto. Como puede ver en el código de ejemplo, puede especificar opciones como el delimitador de columna y qué fila (si hay alguna) contiene encabezados de columna (en este caso, el delimitador es una coma y la primera fila contiene los nombres de columna; estos son los configuración predeterminada, por lo que los parámetros podrían haberse omitido).\n",
        "\n",
        "### Manejo de valores perdidos\n",
        "\n",
        "Uno de los problemas más comunes con los que deben lidiar los científicos de datos es la falta de datos o los datos incompletos. Entonces, ¿cómo sabríamos que el DataFrame contiene valores faltantes? Puede usar el método isnull para identificar qué valores individuales son nulos, como este:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqbsyS7PnP8Y"
      },
      "source": [
        "df_students.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_54chHGmncac"
      },
      "source": [
        "Por supuesto, con un DataFrame más grande, sería ineficiente revisar todas las filas y columnas individualmente; para que podamos obtener la suma de los valores perdidos para cada columna, así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YakrRLcKneux"
      },
      "source": [
        "df_students.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ojUtz6nhrr"
      },
      "source": [
        "Ahora sabemos que falta un valor de StudyHours y dos valores de Grade que faltan.\n",
        "\n",
        "Para verlos en contexto, podemos filtrar el marco de datos para incluir solo filas donde cualquiera de las columnas (eje 1 del marco de datos) sea nula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9T05ZYnj4q"
      },
      "source": [
        "df_students[df_students.isnull().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMin7tXEntN2"
      },
      "source": [
        "Cuando se recupera el DataFrame, los valores numéricos faltantes se muestran como NaN (no como un número).\n",
        "\n",
        "Entonces, ahora que hemos encontrado los valores nulos, ¿qué podemos hacer con ellos?\n",
        "\n",
        "Un enfoque común es imputar valores de reemplazo. Por ejemplo, si falta el número de horas de estudio, podríamos simplemente asumir que el estudiante estudió durante un tiempo promedio y reemplazar el valor faltante con la media de horas de estudio. Para hacer esto, podemos usar el método fillna , así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryf2_fBUnv21"
      },
      "source": [
        "df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaH2q1_Ln9gk"
      },
      "source": [
        "Alternativamente, puede ser importante asegurarse de que solo use datos que sepa que son absolutamente correctos; para que pueda eliminar filas o columnas que contienen valores nulos mediante el método dropna . En este caso, eliminaremos filas (eje 0 del DataFrame) donde alguna de las columnas contiene valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgbBNYK3oGMY"
      },
      "source": [
        "df_students = df_students.dropna(axis=0, how='any')\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBsSPoMLoLVp"
      },
      "source": [
        "# Explore los datos en el DataFrame\n",
        "\n",
        "Ahora que hemos limpiado los valores faltantes, estamos listos para explorar los datos en el DataFrame. Comencemos comparando la media de horas de estudio y calificaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhTe34rjoP6m"
      },
      "source": [
        "# Obtenga la media de horas de estudio utilizando el nombre de la columna como índice\n",
        "mean_study = df_students['StudyHours'].mean()\n",
        "\n",
        "# Obtenga la calificación promedio usando el nombre de la columna como una propiedad (¡solo para aclarar el punto!)\n",
        "mean_grade = df_students.Grade.mean()\n",
        "\n",
        "# Imprime la media de horas de estudio y la nota media\n",
        "print('Average weekly study hours: {:.2f}\\nAverage grade: {:.2f}'.format(mean_study, mean_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPPNt_hoY5C"
      },
      "source": [
        "De acuerdo, filtremos el DataFrame para encontrar solo los estudiantes que estudiaron por más de la cantidad de tiempo promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ueK_WCoa5D"
      },
      "source": [
        "# Obtenga estudiantes que estudiaron durante la media o más horas\n",
        "df_students[df_students.StudyHours > mean_study]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ADCVHbodOu"
      },
      "source": [
        "Tenga en cuenta que el resultado filtrado es en sí mismo un DataFrame, por lo que puede trabajar con sus columnas como cualquier otro DataFrame.\n",
        "\n",
        "Por ejemplo, busquemos la calificación promedio de los estudiantes que realizaron más tiempo de estudio que el promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjXC9RtUol3L"
      },
      "source": [
        "# ¿Cuál fue su nota media?\n",
        "df_students[df_students.StudyHours > mean_study].Grade.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdHaKm6dop0O"
      },
      "source": [
        "Supongamos que la calificación aprobatoria del curso es 60.\n",
        "\n",
        "Podemos usar esa información para agregar una nueva columna al DataFrame, indicando si cada estudiante aprobó o no.\n",
        "\n",
        "Primero, crearemos una Serie Pandas que contiene el indicador de pasa / falla (Verdadero o Falso), y luego concatenamos esa serie como una nueva columna (eje 1) en el DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHintfZopNQ"
      },
      "source": [
        "passes  = pd.Series(df_students['Grade'] >= 60)\n",
        "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejAoorFjoyt-"
      },
      "source": [
        "Los DataFrames están diseñados para datos tabulares y puede utilizarlos para realizar muchos de los tipos de operaciones de análisis de datos que puede realizar en una base de datos relacional; como agrupar y agregar tablas de datos.\n",
        "\n",
        "Por ejemplo, puede usar el método groupby para agrupar los datos de los estudiantes en grupos según la columna de Aprobado que agregó anteriormente y contar el número de nombres en cada grupo; en otras palabras, puede determinar cuántos estudiantes aprobaron y reprobaron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFTJIkyUo0k5"
      },
      "source": [
        "print(df_students.groupby(df_students.Pass).Name.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYUVg9RUo5OO"
      },
      "source": [
        "Puede agregar varios campos en un grupo utilizando cualquier función de agregación disponible. Por ejemplo, puede encontrar el tiempo medio de estudio y la calificación de los grupos de estudiantes que aprobaron y reprobaron el curso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L1momp1o8ry"
      },
      "source": [
        "print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdPffPt8pAy3"
      },
      "source": [
        "Los DataFrames son increíblemente versátiles y facilitan la manipulación de datos. Muchas operaciones de DataFrame devuelven una nueva copia del DataFrame; por lo que si desea modificar un DataFrame pero mantener la variable existente, debe asignar el resultado de la operación a la variable existente. Por ejemplo, el siguiente código ordena los datos de los estudiantes en orden descendente de Grado y asigna el DataFrame ordenado resultante a la variable df_students original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afDBEllVpGjg"
      },
      "source": [
        "# Cree un DataFrame con los datos ordenados por grado (descendente)\n",
        "df_students = df_students.sort_values('Grade', ascending=False)\n",
        "# Muestra el DataFrame\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOUDlLS_OT5P"
      },
      "source": [
        "## Resumen\n",
        "###¡Eso es todo por ahora!\n",
        "\n",
        "Numpy y DataFrames son los caballos de batalla de la ciencia de datos en Python. Nos proporcionan formas de cargar, explorar y analizar datos tabulares. Como veremos en los módulos siguientes, incluso los métodos de análisis avanzados suelen depender de Numpy y Pandas para estos importantes roles.\n",
        "\n",
        "En nuestro próximo libro de trabajo, veremos cómo crear gráficos y explorar sus datos de formas más interesantes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSzQqw0rznMJ"
      },
      "source": [
        "# Visualizar datos\n",
        "\n",
        "Los científicos de datos visualizan los datos para comprenderlos mejor. Esto puede significar mirar los datos brutos, medidas de resumen como promedios o graficar los datos. Los gráficos son un medio poderoso para ver datos, ya que podemos discernir patrones moderadamente complejos rápidamente sin necesidad de definir medidas de resumen matemáticas.\n",
        "\n",
        "## Representar datos visualmente\n",
        "\n",
        "Representar datos visualmente normalmente significa graficarlos. Esto se hace para proporcionar una evaluación cualitativa rápida de nuestros datos, que puede ser útil para comprender los resultados, encontrar valores atípicos, comprender cómo se distribuyen los números, etc.\n",
        "\n",
        "Si bien a veces sabemos de antemano qué tipo de gráfico será más útil, otras veces los usamos de manera exploratoria. Para comprender el poder de la visualización de datos, considere los siguientes datos: la ubicación (x, y) de un automóvil autónomo. En su forma cruda, es difícil ver patrones reales. La media o promedio nos dice que su camino se centró alrededor de x = 0.2 ey = 0.3, y el rango de números parece estar entre -2 y 2.\n",
        "\n",
        "![An image](https://raw.githubusercontent.com/MariaDelCarmenHernandezDiaz/Recursos-Test/main/universidad/Captura.PNG)\n",
        "\n",
        "Si ahora graficamos la Ubicación-X a lo largo del tiempo, podemos ver que parece que tenemos algunos valores perdidos entre los tiempos 7 y 12.\n",
        "\n",
        "![An image](https://docs.microsoft.com/en-us/learn/modules/explore-analyze-data-with-python/media/4-x-coordinates.png)\n",
        "\n",
        "Si graficamos X vs Y, terminamos con un mapa de dónde ha conducido el automóvil. Al instante es obvio que el automóvil ha estado conduciendo en círculo, pero en algún momento condujo hacia el centro de ese círculo.\n",
        "\n",
        "![An image](https://docs.microsoft.com/en-us/learn/modules/explore-analyze-data-with-python/media/4-x-y-coordinates.png)\n",
        "\n",
        "Los gráficos no se limitan a diagramas de dispersión 2D como los anteriores, sino que se pueden usar para explorar otros tipos de datos, como proporciones, que se muestran a través de gráficos circulares, gráficos de barras apiladas, cómo se distribuyen los datos, con histogramas, diagramas de caja y bigotes, y cómo se diferencian dos conjuntos de datos. A menudo, cuando intentamos comprender datos o resultados sin procesar, es posible que experimentemos con diferentes tipos de gráficos hasta que encontremos uno que explique los datos de una manera visualmente intuitiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrBR52Jw1iGZ"
      },
      "source": [
        "# Ejercicio: visualizar datos con Matplotlib.\n",
        "\n",
        "Este módulo requiere una caja de arena para completarse. Una caja de arena le da acceso a recursos gratuitos. No se cobrará su suscripción personal. La zona de pruebas solo se puede utilizar para completar la formación en Microsoft Learn. El uso por cualquier otro motivo está prohibido y puede resultar en la pérdida permanente del acceso a la caja de arena.\n",
        "\n",
        "# Explorar datos con Python: visualizar datos.\n",
        "\n",
        "En este cuaderno, aplicaremos técnicas básicas para analizar datos con estadísticas básicas y visualizar mediante gráficos.\n",
        "\n",
        "## Cargando nuestros datos.\n",
        "\n",
        "Antes de empezar, carguemos los mismos datos sobre las horas de estudio que analizamos en el cuaderno anterior. También volveremos a calcular quién pasó de la misma manera que la última vez. Ejecute el código en la celda de abajo haciendo clic en el botón **► Ejecutar** para ver los datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlKU_z4F1_Jk"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from a text file\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
        "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
        "\n",
        "# Remove any rows with missing data\n",
        "df_students = df_students.dropna(axis=0, how='any')\n",
        "\n",
        "# Calculate who passed, assuming '60' is the grade needed to pass\n",
        "passes  = pd.Series(df_students['Grade'] >= 60)\n",
        "\n",
        "# Save who passed to the Pandas dataframe\n",
        "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
        "\n",
        "\n",
        "# Print the result out into this notebook\n",
        "df_students "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ret6kPhx2Bi8"
      },
      "source": [
        "# Visualización de datos con Matplotlib.\n",
        "\n",
        "Los DataFrames brindan una excelente manera de explorar y analizar datos tabulares, pero a veces una imagen vale más que mil filas y columnas. La biblioteca Matplotlib proporciona la base para trazar visualizaciones de datos que pueden mejorar en gran medida su capacidad para analizar los datos.\n",
        "\n",
        "Comencemos con una gráfica de barras simple que muestra la calificación de cada estudiante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCOXMqxM2J_j"
      },
      "source": [
        "# Ensure plots are displayed inline in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a bar plot of name vs grade\n",
        "plt.bar(x=df_students.Name, height=df_students.Grade)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFpHTT2v2Qyb"
      },
      "source": [
        "Bueno, eso funcionó; pero el gráfico podría necesitar algunas mejoras para aclarar lo que estamos viendo.\n",
        "\n",
        "Tenga en cuenta que utilizó la clase pyplot de Matplotlib para trazar el gráfico. Esta clase proporciona un montón de formas de mejorar los elementos visuales de la trama. Por ejemplo, el siguiente código:\n",
        "\n",
        "* Especifica el color del gráfico de barras.\n",
        "* Agrega un título al gráfico (para que sepamos lo que representa)\n",
        "* Agrega etiquetas a X e Y (para que sepamos qué eje muestra qué datos)\n",
        "* Agrega una cuadrícula (para facilitar la determinación de los valores de las barras)\n",
        "* Gira los marcadores X (para que podamos leerlos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClMNez-A2f_T"
      },
      "source": [
        "# Create a bar plot of name vs grade\n",
        "plt.bar(x=df_students.Name, height=df_students.Grade, color='orange')\n",
        "\n",
        "# Customize the chart\n",
        "plt.title('Student Grades')\n",
        "plt.xlabel('Student')\n",
        "plt.ylabel('Grade')\n",
        "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz_zqLSd2jr9"
      },
      "source": [
        "Una trama está técnicamente contenida con una figura . En los ejemplos anteriores, la figura se creó implícitamente para usted; pero puedes crearlo explícitamente. Por ejemplo, el siguiente código crea una figura con un tamaño específico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk_hcMD22nfR"
      },
      "source": [
        "# Create a Figure\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "\n",
        "# Create a bar plot of name vs grade\n",
        "plt.bar(x=df_students.Name, height=df_students.Grade, color='orange')\n",
        "\n",
        "# Customize the chart\n",
        "plt.title('Student Grades')\n",
        "plt.xlabel('Student')\n",
        "plt.ylabel('Grade')\n",
        "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mInQHU22q0v"
      },
      "source": [
        "Una figura puede contener múltiples subtramas, cada una en su propio eje .\n",
        "\n",
        "Por ejemplo, el siguiente código crea una figura con dos subtramas: una es un gráfico de barras que muestra las calificaciones de los estudiantes y el otro es un gráfico circular que compara el número de calificaciones aprobatorias con las no aprobadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ukm2BmQ2zCo"
      },
      "source": [
        "# Create a figure for 2 subplots (1 row, 2 columns)\n",
        "fig, ax = plt.subplots(1, 2, figsize = (10,4))\n",
        "\n",
        "# Create a bar plot of name vs grade on the first axis\n",
        "ax[0].bar(x=df_students.Name, height=df_students.Grade, color='orange')\n",
        "ax[0].set_title('Grades')\n",
        "ax[0].set_xticklabels(df_students.Name, rotation=90)\n",
        "\n",
        "# Create a pie chart of pass counts on the second axis\n",
        "pass_counts = df_students['Pass'].value_counts()\n",
        "ax[1].pie(pass_counts, labels=pass_counts)\n",
        "ax[1].set_title('Passing Grades')\n",
        "ax[1].legend(pass_counts.keys().tolist())\n",
        "\n",
        "# Add a title to the Figure\n",
        "fig.suptitle('Student Data')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49nyROF62z-i"
      },
      "source": [
        "Hasta ahora, ha utilizado métodos del objeto Matplotlib.pyplot para trazar gráficos. Sin embargo, Matplotlib es tan fundamental para los gráficos en Python que muchos paquetes, incluido Pandas, proporcionan métodos que abstraen las funciones subyacentes de Matplotlib y simplifican el trazado. Por ejemplo, el DataFrame proporciona sus propios métodos para trazar datos, como se muestra en el siguiente ejemplo para trazar un gráfico de barras de horas de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQ7SJy6287o"
      },
      "source": [
        "df_students.plot.bar(x='Name', y='StudyHours', color='teal', figsize=(6,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B2ExP4z2_Ml"
      },
      "source": [
        "### Empezando con el análisis estadístico\n",
        "Ahora que sabe cómo usar Python para manipular y visualizar datos, puede comenzar a analizarlos.\n",
        "\n",
        "Gran parte de la ciencia de datos tiene sus raíces en las estadísticas , por lo que exploraremos algunas técnicas estadísticas básicas.\n",
        "\n",
        "**Nota** : esto esno tiene la intención de enseñarle estadísticas, es un tema demasiado grande para este cuaderno. Sin embargo, le presentará algunos conceptos y técnicas estadísticos que los científicos de datos utilizan mientras exploran datos en preparación para el modelado de aprendizaje automático.\n",
        "\n",
        "### Estadística descriptiva y distribución de datos\n",
        "\n",
        "Al examinar una variable (por ejemplo, una muestra de las calificaciones de los estudiantes), los científicos de datos están particularmente interesados en su distribución (en otras palabras, cómo se distribuyen los diferentes valores de calificación en la muestra). El punto de partida de esta exploración suele ser visualizar los datos como un histograma y ver con qué frecuencia se produce cada valor de la variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tBjKLMN3Oo8"
      },
      "source": [
        "# Get the variable to examine\n",
        "var_data = df_students['Grade']\n",
        "\n",
        "# Create a Figure\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "# Plot a histogram\n",
        "plt.hist(var_data)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Data Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJegEWqv3Qjl"
      },
      "source": [
        "El histograma de calificaciones tiene una forma simétrica, donde las calificaciones que ocurren con más frecuencia tienden a estar en el medio del rango (alrededor de 50), con menos calificaciones en los extremos de la escala.\n",
        "\n",
        "### Medidas de tendencia central\n",
        "Para comprender mejor la distribución, podemos examinar las llamadas medidas de tendencia central ; que es una forma elegante de describir las estadísticas que representan el \"medio\" de los datos. El objetivo de esto es intentar encontrar un valor \"típico\". Las formas comunes de definir la mitad de los datos incluyen:\n",
        "\n",
        "* La media : Un promedio simple basado en la suma de todos los valores del conjunto de muestras y luego dividiendo el total por el número de muestras.\n",
        "* La mediana : el valor en el medio del rango de todos los valores de la muestra.\n",
        "* La moda : el valor más común en el conjunto de muestra* .\n",
        "\n",
        "Calculemos estos valores, junto con los valores mínimo y máximo para la comparación, y mostrémoslos en el histograma.\n",
        "\n",
        "* Por supuesto, en algunos conjuntos de muestras, puede haber un empate para el valor más común, en cuyo caso el conjunto de datos se describe como bimodal o incluso multimodal ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYDzgnpp3k6K"
      },
      "source": [
        "# Get the variable to examine\n",
        "var = df_students['Grade']\n",
        "\n",
        "# Get statistics\n",
        "min_val = var.min()\n",
        "max_val = var.max()\n",
        "mean_val = var.mean()\n",
        "med_val = var.median()\n",
        "mod_val = var.mode()[0]\n",
        "\n",
        "print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
        "  mean_val,\n",
        "  med_val,\n",
        "  mod_val,\n",
        "  max_val))\n",
        "\n",
        "# Create a Figure\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "# Plot a histogram\n",
        "plt.hist(var)\n",
        "\n",
        "# Add lines for the statistics\n",
        "plt.axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "plt.axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "plt.axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
        "plt.axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "plt.axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Data Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI7GgzIF352q"
      },
      "source": [
        "Para los datos de calificaciones, la media, la mediana y la moda parecen estar más o menos en el medio del mínimo y el máximo, alrededor de 50.\n",
        "\n",
        "Otra forma de visualizar la distribución de una variable es usar un diagrama de caja (a veces llamado diagrama de caja y bigotes ). Creemos uno para los datos de calificaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6XnepkR3z-L"
      },
      "source": [
        "# Get the variable to examine\n",
        "var = df_students['Grade']\n",
        "\n",
        "# Create a Figure\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "# Plot a histogram\n",
        "plt.boxplot(var)\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Data Distribution')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCDsH9wF394A"
      },
      "source": [
        "El diagrama de caja muestra la distribución de los valores de calificación en un formato diferente al histograma. La parte del cuadro del gráfico muestra dónde residen los dos cuartiles internos de los datos, por lo que en este caso, la mitad de las calificaciones están entre aproximadamente 36 y 63. Los bigotes que se extienden desde el cuadro muestran los dos cuartiles externos; por lo que la otra mitad de las calificaciones en este caso están entre 0 y 36 o 63 y 100. La línea en el cuadro indica el valor mediano .\n",
        "\n",
        "Para aprender, puede ser útil combinar histogramas y diagramas de caja, con la orientación del diagrama de caja cambiada para alinearla con el histograma (de alguna manera, puede ser útil pensar en el histograma como una vista de \"elevación frontal\" de la distribución y el diagrama de caja como una vista en \"planta\" de la distribución desde arriba)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vG3agmm4Rw-"
      },
      "source": [
        "# Create a function that we can re-use\n",
        "def show_distribution(var_data):\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    # Get statistics\n",
        "    min_val = var_data.min()\n",
        "    max_val = var_data.max()\n",
        "    mean_val = var_data.mean()\n",
        "    med_val = var_data.median()\n",
        "    mod_val = var_data.mode()[0]\n",
        "\n",
        "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
        "                                                                                            mean_val,\n",
        "                                                                                            med_val,\n",
        "                                                                                            mod_val,\n",
        "                                                                                            max_val))\n",
        "\n",
        "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
        "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
        "\n",
        "    # Plot the histogram   \n",
        "    ax[0].hist(var_data)\n",
        "    ax[0].set_ylabel('Frequency')\n",
        "\n",
        "    # Add lines for the mean, median, and mode\n",
        "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Plot the boxplot   \n",
        "    ax[1].boxplot(var_data, vert=False)\n",
        "    ax[1].set_xlabel('Value')\n",
        "\n",
        "    # Add a title to the Figure\n",
        "    fig.suptitle('Data Distribution')\n",
        "\n",
        "    # Show the figure\n",
        "    fig.show()\n",
        "\n",
        "# Get the variable to examine\n",
        "col = df_students['Grade']\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoPQ5eN4caA"
      },
      "source": [
        "Todas las medidas de tendencia central están justo en el medio de la distribución de datos, que es simétrica con valores que se vuelven progresivamente más bajos en ambas direcciones desde el medio.\n",
        "\n",
        "Para explorar esta distribución con más detalle, debe comprender que la estadística se trata fundamentalmente de tomar muestras de datos y utilizar funciones de probabilidad para extrapolar información sobre la población completa de datos.\n",
        "\n",
        "¿Qué significa esto? Las muestras se refieren a los datos que tenemos a mano, como información sobre los hábitos de estudio y las calificaciones de estos 22 estudiantes. La población se refiere a todos los datos posibles que pudimos recopilar, como las calificaciones y los hábitos de estudio de cada estudiante en todas las instituciones educativas a lo largo de la historia. Por lo general, estamos interesados en la población, pero simplemente no es práctico recopilar todos esos datos. En cambio, debemos intentar estimar cómo es la población a partir de la pequeña cantidad de datos (muestras) que tenemos.\n",
        "\n",
        "Si tenemos suficientes muestras, podemos calcular algo llamado función de densidad de probabilidad , que estima la distribución de calificaciones para la población completa.\n",
        "\n",
        "La clase Pandas DataFrame proporciona una función de trazado útil para mostrar esta densidad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIviGfL94dTb"
      },
      "source": [
        "def show_density(var_data):\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "    # Plot density\n",
        "    var_data.plot.density()\n",
        "\n",
        "    # Add titles and labels\n",
        "    plt.title('Data Density')\n",
        "\n",
        "    # Show the mean, median, and mode\n",
        "    plt.axvline(x=var_data.mean(), color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.median(), color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.mode()[0], color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Show the figure\n",
        "    plt.show()\n",
        "\n",
        "# Get the density of Grade\n",
        "col = df_students['Grade']\n",
        "show_density(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFASjwha4hOR"
      },
      "source": [
        "Como se esperaba del histograma de la muestra, la densidad muestra la característica \"curva de campana\" de lo que los estadísticos llaman una distribución normal con la media y la moda en el centro y colas simétricas.\n",
        "\n",
        "### Resumen\n",
        "¡Bien hecho! Había una serie de conceptos nuevos aquí, así que resumamos.\n",
        "\n",
        "Aquí tenemos:\n",
        "\n",
        "1. Hizo gráficos con matplotlib\n",
        "2. Visto cómo personalizar estos gráficos\n",
        "3. Estadísticas básicas calculadas, como medianas\n",
        "4. Observó la distribución de los datos mediante diagramas de caja e histogramas.\n",
        "5. Aprendió sobre muestras vs poblaciones\n",
        "6. Estimación de cómo se vería la población de graphse a partir de una muestra de calificaciones.\n",
        "\n",
        "En nuestro próximo cuaderno veremos cómo detectar datos inusuales y encontrar relaciones entre los datos.\n",
        "\n",
        "### Otras lecturas\n",
        "\n",
        "Para obtener más información sobre los paquetes de Python que exploró en este cuaderno, consulte la siguiente documentación:\n",
        "\n",
        "* NumPy\n",
        "* Pandas\n",
        "* Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df_ntmTH5AEo"
      },
      "source": [
        "# Examinar datos del mundo real\n",
        "Terminado.\n",
        "\n",
        "Los datos presentados en el material educativo suelen ser notablemente perfectos y están diseñados para mostrar a los estudiantes cómo encontrar relaciones claras entre las variables. Los datos del 'mundo real' son un poco menos simples.\n",
        "\n",
        "Debido a la complejidad de los datos del 'mundo real', los datos sin procesar deben inspeccionarse para detectar problemas antes de usarlos.\n",
        "\n",
        "Como tal, la mejor práctica es inspeccionar los datos sin procesar y procesarlos antes de usarlos, lo que reduce los errores o problemas, generalmente eliminando puntos de datos erróneos o modificando los datos en una forma más útil.\n",
        "\n",
        "# Problemas de datos del mundo real\n",
        "\n",
        "Los datos del mundo real pueden contener muchos problemas diferentes que pueden afectar la utilidad de los datos y nuestra interpretación de los resultados.\n",
        "\n",
        "Es importante darse cuenta de que la mayoría de los datos del mundo real están influenciados por factores que no se registraron en ese momento. Por ejemplo, podríamos tener una tabla de tiempos de pista de autos de carrera junto con los tamaños de los motores, pero varios otros factores que no se anotaron, como el clima, probablemente también influyeron. Si es problemático, la influencia de estos factores a menudo se puede reducir aumentando el tamaño del conjunto de datos.\n",
        "\n",
        "En otras situaciones, los puntos de datos que están claramente fuera de lo esperado, también conocidos como \" valores atípicos \", a veces se pueden eliminar de forma segura de los análisis, aunque se debe tener cuidado de no eliminar los puntos de datos que proporcionan información real.\n",
        "\n",
        "Otro problema común en los datos del mundo real es el sesgo. El sesgo se refiere a una tendencia a seleccionar ciertos tipos de valores con más frecuencia que otros, de una manera que tergiversa la población subyacente o el \"mundo real\". A veces, el sesgo se puede identificar mediante la exploración de datos teniendo en cuenta los conocimientos básicos sobre el origen de los datos.\n",
        "\n",
        "Recuerde, los datos del mundo real siempre tendrán problemas, pero este suele ser un problema superable. Recuerda:\n",
        "\n",
        "* Compruebe si faltan valores y datos mal registrados\n",
        "* Considere la eliminación de valores atípicos obvios\n",
        "* Considere qué factores del mundo real podrían afectar su análisis y considere si el tamaño de su conjunto de datos es lo suficientemente grande para manejar esto\n",
        "* Compruebe si hay datos brutos sesgados y considere sus opciones para solucionar este problema, si se encuentran"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnCj_-J05YwG"
      },
      "source": [
        "## Explorando datos con Python: datos del mundo real\n",
        "\n",
        "La última vez, analizamos las calificaciones de los datos de nuestros estudiantes y lo investigamos visualmente con histogramas y diagramas de caja. Ahora veremos casos más complejos, describiremos los datos de manera más completa y discutiremos cómo hacer comparaciones básicas entre los datos.\n",
        "\n",
        "### Distribuciones de datos del mundo real\n",
        "\n",
        "La última vez, analizamos las calificaciones de los datos de nuestros estudiantes y estimamos a partir de esta muestra cómo se vería la población completa de calificaciones. Solo para actualizar, echemos un vistazo a estos datos nuevamente.\n",
        "\n",
        "Ejecute el siguiente código para imprimir los datos y hacer un histograma + diagrama de caja que muestre las calificaciones de nuestra muestra de estudiantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ127jwn5pZ_"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load data from a text file\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
        "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
        "\n",
        "# Remove any rows with missing data\n",
        "df_students = df_students.dropna(axis=0, how='any')\n",
        "\n",
        "# Calculate who passed, assuming '60' is the grade needed to pass\n",
        "passes  = pd.Series(df_students['Grade'] >= 60)\n",
        "\n",
        "# Save who passed to the Pandas dataframe\n",
        "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
        "\n",
        "\n",
        "# Print the result out into this notebook\n",
        "print(df_students)\n",
        "\n",
        "\n",
        "# Create a function that we can re-use\n",
        "def show_distribution(var_data):\n",
        "    '''\n",
        "    This function will make a distribution (graph) and display it\n",
        "    '''\n",
        "\n",
        "    # Get statistics\n",
        "    min_val = var_data.min()\n",
        "    max_val = var_data.max()\n",
        "    mean_val = var_data.mean()\n",
        "    med_val = var_data.median()\n",
        "    mod_val = var_data.mode()[0]\n",
        "\n",
        "    print('Minimum:{:.2f}\\nMean:{:.2f}\\nMedian:{:.2f}\\nMode:{:.2f}\\nMaximum:{:.2f}\\n'.format(min_val,\n",
        "                                                                                            mean_val,\n",
        "                                                                                            med_val,\n",
        "                                                                                            mod_val,\n",
        "                                                                                            max_val))\n",
        "\n",
        "    # Create a figure for 2 subplots (2 rows, 1 column)\n",
        "    fig, ax = plt.subplots(2, 1, figsize = (10,4))\n",
        "\n",
        "    # Plot the histogram   \n",
        "    ax[0].hist(var_data)\n",
        "    ax[0].set_ylabel('Frequency')\n",
        "\n",
        "    # Add lines for the mean, median, and mode\n",
        "    ax[0].axvline(x=min_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mean_val, color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=med_val, color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=mod_val, color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "    ax[0].axvline(x=max_val, color = 'gray', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Plot the boxplot   \n",
        "    ax[1].boxplot(var_data, vert=False)\n",
        "    ax[1].set_xlabel('Value')\n",
        "\n",
        "    # Add a title to the Figure\n",
        "    fig.suptitle('Data Distribution')\n",
        "\n",
        "    # Show the figure\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "show_distribution(df_students['Grade'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iye0zOtm5z7V"
      },
      "source": [
        "Como recordará, nuestros datos tenían la media y la moda en el centro, con datos distribuidos simétricamente desde allí.\n",
        "\n",
        "Ahora echemos un vistazo a la distribución de los datos de las horas de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsU2TwTR503O"
      },
      "source": [
        "# Get the variable to examine\n",
        "col = df_students['StudyHours']\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ka1J3di54t8"
      },
      "source": [
        "La distribución de los datos del tiempo de estudio es significativamente diferente a la de los grados.\n",
        "\n",
        "Tenga en cuenta que los bigotes del diagrama de caja solo comienzan alrededor de 6.0, lo que indica que la gran mayoría del primer trimestre de los datos está por encima de este valor. El mínimo está marcado con una o , lo que indica que es estadísticamente un valor atípico , un valor que se encuentra significativamente fuera del rango del resto de la distribución.\n",
        "\n",
        "Los valores atípicos pueden ocurrir por muchas razones. Tal vez un estudiante tenía la intención de registrar \"10\" horas de tiempo de estudio, pero ingresó \"1\" y perdió el \"0\". ¡O tal vez el estudiante era anormalmente perezoso cuando se trata de estudiar! De cualquier manera, es una anomalía estadística que no representa a un estudiante típico. Veamos cómo se ve la distribución sin él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjSJF96K6VH8"
      },
      "source": [
        "# Get the variable to examine\n",
        "# We will only get students who have studied more than one hour\n",
        "col = df_students[df_students.StudyHours>1]['StudyHours']\n",
        "\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG9uDBFG6aNI"
      },
      "source": [
        "Para fines de aprendizaje, acabamos de tratar que el valor 1 es un valor atípico y lo excluimos. En el mundo real, sin embargo, sería inusual excluir datos en los extremos sin más justificación cuando el tamaño de nuestra muestra es tan pequeño. Esto se debe a que cuanto menor sea el tamaño de nuestra muestra, más probable es que nuestra muestra sea una mala representación de toda la población (aquí, la población significa calificaciones para todos los estudiantes, no solo para nuestros 22). Por ejemplo, si tomamos una muestra del tiempo de estudio de otros 1000 estudiantes, ¡podríamos encontrar que en realidad es bastante común no estudiar mucho!\n",
        "\n",
        "Cuando tenemos más datos disponibles, nuestra muestra se vuelve más confiable. Esto hace que sea más fácil considerar valores atípicos como valores que caen por debajo o por encima de los percentiles dentro de los cuales se encuentran la mayoría de los datos. Por ejemplo, el siguiente código usa la función de cuantil de Pandas para excluir observaciones por debajo del percentil 0.01 (el valor por encima del cual reside el 99% de los datos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF6CHjgG6d8v"
      },
      "source": [
        "# calculate the 0.01th percentile\n",
        "q01 = df_students.StudyHours.quantile(0.01)\n",
        "# Get the variable to examine\n",
        "col = df_students[df_students.StudyHours>q01]['StudyHours']\n",
        "# Call the function\n",
        "show_distribution(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB5XuZ4Y6jai"
      },
      "source": [
        "> **Sugerencia**: también puede eliminar los valores atípicos en el extremo superior de la distribución definiendo un umbral en un valor de percentil alto; por ejemplo, puede usar la función de cuantiles para encontrar el percentil 0,99 por debajo del cual reside el 99% de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjq9mJR26p0d"
      },
      "source": [
        "Con los valores atípicos eliminados, el diagrama de caja muestra todos los datos dentro de los cuatro cuartiles. Sin embargo, tenga en cuenta que la distribución no es simétrica como lo es para los datos de calificaciones: hay algunos estudiantes con tiempos de estudio muy altos de alrededor de 16 horas, pero la mayor parte de los datos está entre 7 y 13 horas; Los pocos valores extremadamente altos empujan la media hacia el extremo superior de la escala.\n",
        "\n",
        "Veamos la densidad de esta distribución."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcImCnHK6sO6"
      },
      "source": [
        "def show_density(var_data):\n",
        "    fig = plt.figure(figsize=(10,4))\n",
        "\n",
        "    # Plot density\n",
        "    var_data.plot.density()\n",
        "\n",
        "    # Add titles and labels\n",
        "    plt.title('Data Density')\n",
        "\n",
        "    # Show the mean, median, and mode\n",
        "    plt.axvline(x=var_data.mean(), color = 'cyan', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.median(), color = 'red', linestyle='dashed', linewidth = 2)\n",
        "    plt.axvline(x=var_data.mode()[0], color = 'yellow', linestyle='dashed', linewidth = 2)\n",
        "\n",
        "    # Show the figure\n",
        "    plt.show()\n",
        "\n",
        "# Get the density of StudyHours\n",
        "show_density(col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JnD3h0A6y3r"
      },
      "source": [
        "Este tipo de distribución se llama sesgada a la derecha . La masa de los datos está en el lado izquierdo de la distribución, creando una cola larga a la derecha debido a los valores en el extremo superior; que tiran de la media hacia la derecha.\n",
        "\n",
        "### Medidas de varianza\n",
        "Así que ahora tenemos una buena idea de dónde están las distribuciones de datos de la mitad de la calificación y las horas de estudio. Sin embargo, hay otro aspecto de las distribuciones que deberíamos examinar: ¿cuánta variabilidad hay en los datos?\n",
        "\n",
        "Las estadísticas típicas que miden la variabilidad en los datos incluyen:\n",
        "\n",
        "* Rango: la diferencia entre el máximo y el mínimo. No hay incorporado en función de esto, pero es fácil de calcular utilizando el min y max funciones.\n",
        "* Varianza: el promedio de la diferencia al cuadrado de la media. Puede usar la función var incorporada para encontrar esto.\n",
        "* Desviación estándar : la raíz cuadrada de la varianza. Puede usar la función estándar incorporada para encontrar esto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ys8K6RA7CNK"
      },
      "source": [
        "for col_name in ['Grade','StudyHours']:\n",
        "    col = df_students[col_name]\n",
        "    rng = col.max() - col.min()\n",
        "    var = col.var()\n",
        "    std = col.std()\n",
        "    print('\\n{}:\\n - Range: {:.2f}\\n - Variance: {:.2f}\\n - Std.Dev: {:.2f}'.format(col_name, rng, var, std))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LJQU5lf7DQo"
      },
      "source": [
        "De estas estadísticas, la desviación estándar es generalmente la más útil. Proporciona una medida de la varianza de los datos en la misma escala que los propios datos (por lo tanto, puntos de calificación para la distribución de calificaciones y horas para la distribución de horas de estudio). Cuanto mayor es la desviación estándar, mayor es la varianza cuando se comparan los valores de la distribución con la media de la distribución; en otras palabras, los datos están más dispersos.\n",
        "\n",
        "Cuando se trabaja con una distribución normal , la desviación estándar trabaja con las características particulares de una distribución normal para proporcionar una comprensión aún mayor. Ejecute la celda a continuación para ver la relación entre las desviaciones estándar y los datos en la distribución normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rqhcKeV7K7y"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Get the Grade column\n",
        "col = df_students['Grade']\n",
        "\n",
        "# get the density\n",
        "density = stats.gaussian_kde(col)\n",
        "\n",
        "# Plot the density\n",
        "col.plot.density()\n",
        "\n",
        "# Get the mean and standard deviation\n",
        "s = col.std()\n",
        "m = col.mean()\n",
        "\n",
        "# Annotate 1 stdev\n",
        "x1 = [m-s, m+s]\n",
        "y1 = density(x1)\n",
        "plt.plot(x1,y1, color='magenta')\n",
        "plt.annotate('1 std (68.26%)', (x1[1],y1[1]))\n",
        "\n",
        "# Annotate 2 stdevs\n",
        "x2 = [m-(s*2), m+(s*2)]\n",
        "y2 = density(x2)\n",
        "plt.plot(x2,y2, color='green')\n",
        "plt.annotate('2 std (95.45%)', (x2[1],y2[1]))\n",
        "\n",
        "# Annotate 3 stdevs\n",
        "x3 = [m-(s*3), m+(s*3)]\n",
        "y3 = density(x3)\n",
        "plt.plot(x3,y3, color='orange')\n",
        "plt.annotate('3 std (99.73%)', (x3[1],y3[1]))\n",
        "\n",
        "# Show the location of the mean\n",
        "plt.axvline(col.mean(), color='cyan', linestyle='dashed', linewidth=1)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqmSqIz37PT6"
      },
      "source": [
        "Las líneas horizontales muestran el porcentaje de datos dentro de 1, 2 y 3 desviaciones estándar de la media (más o menos).\n",
        "\n",
        "En cualquier distribución normal:\n",
        "\n",
        "* Aproximadamente el 68,26% de los valores se encuentran dentro de una desviación estándar de la media.\n",
        "* Aproximadamente el 95,45% de los valores se encuentran dentro de dos desviaciones estándar de la media.\n",
        "* Aproximadamente el 99,73% de los valores se encuentran dentro de tres desviaciones estándar de la media.\n",
        "Entonces, como sabemos que la nota media es 49,18, la desviación estándar es 21,74 y la distribución de las notas es aproximadamente normal; podemos calcular que el 68,26% de los alumnos debería alcanzar una nota entre 27,44 y 70,92.\n",
        "\n",
        "Las estadísticas descriptivas que hemos utilizado para comprender la distribución de las variables de datos de los estudiantes son la base del análisis estadístico; y debido a que son una parte tan importante de la exploración de sus datos, hay un método Describe incorporado del objeto DataFrame que devuelve las principales estadísticas descriptivas para todas las columnas numéricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrS83SWr7c1v"
      },
      "source": [
        "df_students.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx6zZPP27gCF"
      },
      "source": [
        "Comparando datos\n",
        "Ahora que sabe algo sobre la distribución estadística de los datos en su conjunto de datos, está listo para examinar sus datos para identificar cualquier relación aparente entre las variables.\n",
        "\n",
        "En primer lugar, eliminemos las filas que contengan valores atípicos para tener una muestra que sea representativa de una clase típica de estudiantes. Identificamos que la columna StudyHours contiene algunos valores atípicos con valores extremadamente bajos, por lo que eliminaremos esas filas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np86AuRJ7kEk"
      },
      "source": [
        "df_sample = df_students[df_students['StudyHours']>1]\n",
        "df_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFh9d0dp7nVS"
      },
      "source": [
        "### Comparación de variables numéricas y categóricas\n",
        "Los datos incluyen dos variables numéricas ( StudyHours y Grade ) y dos variables categóricas ( Name y Pass ). Comencemos comparando la columna numérica StudyHours con la columna categórica Aprobado para ver si existe una relación aparente entre la cantidad de horas estudiadas y una calificación aprobatoria.\n",
        "\n",
        "Para hacer esta comparación, creemos diagramas de caja que muestren la distribución de StudyHours para cada posible valor de Aprobación (verdadero y falso)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGhARoh47vKK"
      },
      "source": [
        "df_sample.boxplot(column='StudyHours', by='Pass', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cEWKn5c7yzt"
      },
      "source": [
        "Al comparar las distribuciones de StudyHours, es inmediatamente evidente (si no particularmente sorprendente) que los estudiantes que aprobaron el curso tendieron a estudiar más horas que los estudiantes que no lo hicieron. Entonces, si desea predecir si es probable que un estudiante apruebe o no el curso, la cantidad de tiempo que pasa estudiando puede ser una buena característica de predicción.\n",
        "\n",
        "### Comparar variables numéricas\n",
        "\n",
        "Ahora comparemos dos variables numéricas. Comenzaremos creando un gráfico de barras que muestre las calificaciones y las horas de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YF3zXX79f7"
      },
      "source": [
        "# Create a bar plot of name vs grade and study hours\n",
        "df_sample.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hDRpRn-8AuE"
      },
      "source": [
        "El gráfico muestra barras para el grado y las horas de estudio de cada estudiante; pero no es fácil de comparar porque los valores están en diferentes escalas. Las calificaciones se miden en puntos de calificación y varían de 3 a 97; mientras que el tiempo de estudio se mide en horas y varía de 1 a 16.\n",
        "\n",
        "Una técnica común cuando se trabaja con datos numéricos en diferentes escalas es normalizar los datos para que los valores mantengan su distribución proporcional, pero se midan en la misma escala. Para lograr esto, usaremos una técnica llamada escala MinMax que distribuye los valores proporcionalmente en una escala de 0 a 1. Puede escribir el código para aplicar esta transformación; pero la biblioteca Scikit-Learn proporciona un escalador para que lo haga por usted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bTLPVs38EL3"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get a scaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Create a new dataframe for the scaled values\n",
        "df_normalized = df_sample[['Name', 'Grade', 'StudyHours']].copy()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "df_normalized[['Grade','StudyHours']] = scaler.fit_transform(df_normalized[['Grade','StudyHours']])\n",
        "\n",
        "# Plot the normalized values\n",
        "df_normalized.plot(x='Name', y=['Grade','StudyHours'], kind='bar', figsize=(8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jsqaWN8LLC"
      },
      "source": [
        "Con los datos normalizados, es más fácil ver una relación aparente entre la calificación y el tiempo de estudio. No es una coincidencia exacta, pero definitivamente parece que los estudiantes con calificaciones más altas tienden a haber estudiado más.\n",
        "\n",
        "Entonces parece haber una correlación entre el tiempo de estudio y la calificación; y de hecho, existe una medida de correlación estadística que podemos utilizar para cuantificar la relación entre estas columnas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbvTjfX28IGK"
      },
      "source": [
        "df_normalized.Grade.corr(df_normalized.StudyHours)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjA-Tp-98axL"
      },
      "source": [
        "La estadística de correlación es un valor entre -1 y 1 que indica la fuerza de una relación. Los valores por encima de 0 indican una correlación positiva (los valores altos de una variable tienden a coincidir con los valores altos de la otra), mientras que los valores por debajo de 0 indican una correlación negativa (los valores altos de una variable tienden a coincidir con los valores bajos de la otra). En este caso, el valor de correlación es cercano a 1; mostrando una correlación fuertemente positiva entre el tiempo de estudio y el grado.\n",
        "\n",
        "> **Nota**: Los científicos de datos suelen citar la máxima \" correlación no es causalidad \". En otras palabras, por muy tentador que sea, no debe interpretar la correlación estadística como una explicación de por qué uno de los valores es alto. En el caso de los datos de los estudiantes, las estadísticas demuestran que los estudiantes con calificaciones altas tienden a tener también una gran cantidad de tiempo de estudio; pero esto no es lo mismo que demostrar que obtuvieron calificaciones altas porque estudiaron mucho. La estadística también podría usarse como evidencia para apoyar la conclusión sin sentido de que los estudiantes estudiaron mucho porque sus calificaciones iban a ser altas.\n",
        "\n",
        "Otra forma de visualizar la aparente correlación entre dos columnas numéricas es usar un diagrama de dispersión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUjRw0908qkB"
      },
      "source": [
        "# Create a scatter plot\n",
        "df_sample.plot.scatter(title='Study Time vs Grade', x='StudyHours', y='Grade')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qyZPLmD8rTP"
      },
      "source": [
        "Nuevamente, parece que hay un patrón discernible en el que los estudiantes que estudiaron más horas son también los estudiantes que obtuvieron las calificaciones más altas.\n",
        "\n",
        "Podemos ver esto más claramente agregando una línea de regresión (o una línea de mejor ajuste ) al gráfico que muestra la tendencia general en los datos. Para hacer esto, usaremos una técnica estadística llamada regresión de mínimos cuadrados .\n",
        "\n",
        "> **Advertencia: ¡matemáticas por delante!** Recuerde cuando estaba aprendiendo a resolver ecuaciones lineales en la escuela y recuerde que la forma pendiente-intersección de una ecuación lineal se ve así: \n",
        "*y = metroX+B*\n",
        "\n",
        "En esta ecuación, y y x son las variables de coordenadas, m es la pendiente de la línea y b es la intersección con el eje y (donde la línea pasa por el eje Y).En el caso de nuestro diagrama de dispersión para los datos de nuestros estudiantes, ya tenemos nuestros valores para x ( StudyHours ) e y ( Grade ), por lo que solo necesitamos calcular la intersección y la pendiente de la línea recta que se encuentra más cerca de esos puntos. Luego podemos formar una ecuación lineal que calcule un nuevo valor de y en esa línea para cada uno de nuestros valores de x ( StudyHours ); para evitar confusiones, llamaremos a este nuevo valor de y f (x) (porque es la salida de un valor lineal ecuación f unción basado en x ). La diferencia entre la y original ( Grado) y el valor de f (x) es el error entre nuestra línea de regresión y la calificación real alcanzada por el estudiante. Nuestro objetivo es calcular la pendiente y la intersección de una línea con el error general más bajo.Específicamente, definimos el error general tomando el error de cada punto, elevándolo al cuadrado y sumando todos los errores al cuadrado. La línea de mejor ajuste es la línea que nos da el valor más bajo para la suma de los errores al cuadrado, de ahí el nombre de regresión por mínimos cuadrados .\n",
        "Afortunadamente, no necesita codificar el cálculo de regresión usted mismo: el paquete SciPy incluye una clase de estadísticas que proporciona un método linregress para hacer el trabajo duro por usted. Esto devuelve (entre otras cosas) los coeficientes que necesita para la ecuación de pendiente: pendiente ( m ) e intersección ( b ) en función de un par de muestras variables que desea comparar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEOss9wO9ReG"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "#\n",
        "df_regression = df_sample[['Grade', 'StudyHours']].copy()\n",
        "\n",
        "# Get the regression slope and intercept\n",
        "m, b, r, p, se = stats.linregress(df_regression['StudyHours'], df_regression['Grade'])\n",
        "print('slope: {:.4f}\\ny-intercept: {:.4f}'.format(m,b))\n",
        "print('so...\\n f(x) = {:.4f}x + {:.4f}'.format(m,b))\n",
        "\n",
        "# Use the function (mx + b) to calculate f(x) for each x (StudyHours) value\n",
        "df_regression['fx'] = (m * df_regression['StudyHours']) + b\n",
        "\n",
        "# Calculate the error between f(x) and the actual y (Grade) value\n",
        "df_regression['error'] = df_regression['fx'] - df_regression['Grade']\n",
        "\n",
        "# Create a scatter plot of Grade vs Salary\n",
        "df_regression.plot.scatter(x='StudyHours', y='Grade')\n",
        "\n",
        "# Plot the regression line\n",
        "plt.plot(df_regression['StudyHours'],df_regression['fx'], color='cyan')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFpSdeKO9SEL"
      },
      "source": [
        "Tenga en cuenta que esta vez, el código trazó dos cosas distintas: el diagrama de dispersión de las horas de estudio de muestra y las calificaciones se trazan como antes, y luego se traza una línea de mejor ajuste basada en los coeficientes de regresión de mínimos cuadrados.\n",
        "\n",
        "Los coeficientes de pendiente e intersección calculados para la línea de regresión se muestran encima del gráfico.\n",
        "\n",
        "La línea se basa en los valores f (x) calculados para cada valor de StudyHours . Ejecute la siguiente celda para ver una tabla que incluye los siguientes valores:\n",
        "\n",
        "* Las horas de estudio para cada alumno.\n",
        "* La nota obtenida por cada alumno.\n",
        "* El valor de f (x) calculado utilizando los coeficientes de la línea de regresión.\n",
        "* El error entre el valor calculado de f (x) y el valor real de la calificación .\n",
        "\n",
        "Algunos de los errores, particularmente en los extremos, y bastante grandes (hasta más de 17,5 puntos); pero en general, la línea se acerca bastante a las calificaciones reales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuOcunos9h9H"
      },
      "source": [
        "# Show the original x,y values, the f(x) value, and the error\n",
        "df_regression[['StudyHours', 'Grade', 'fx', 'error']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv8ZQus99ixp"
      },
      "source": [
        "### Usando los coeficientes de regresión para la predicción\n",
        "\n",
        "Ahora que tiene los coeficientes de regresión para el tiempo de estudio y la relación de calificaciones, puede usarlos en una función para estimar la calificación esperada para una determinada cantidad de estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfAyABJb9oTA"
      },
      "source": [
        "# Define a function based on our regression coefficients\n",
        "def f(x):\n",
        "    m = 6.3134\n",
        "    b = -17.9164\n",
        "    return m*x + b\n",
        "\n",
        "study_time = 14\n",
        "\n",
        "# Get f(x) for study time\n",
        "prediction = f(study_time)\n",
        "\n",
        "# Grade can't be less than 0 or more than 100\n",
        "expected_grade = max(0,min(100,prediction))\n",
        "\n",
        "#Print the estimated grade\n",
        "print ('Studying for {} hours per week may result in a grade of {:.0f}'.format(study_time, expected_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shGuU7Gk9yl8"
      },
      "source": [
        "Entonces, al aplicar estadísticas a los datos de muestra, ha determinado una relación entre el tiempo de estudio y la calificación; y encapsuló esa relación en una función general que puede usarse para predecir una calificación para una cantidad determinada de tiempo de estudio.\n",
        "\n",
        "Esta técnica es, de hecho, la premisa básica del aprendizaje automático. Puede tomar un conjunto de datos de muestra que incluye una o más características (en este caso, la cantidad de horas estudiadas) y un valor de etiqueta conocido (en este caso, la calificación obtenida) y usar los datos de muestra para derivar una función que calcule valores de etiqueta predichos para cualquier conjunto de características.\n",
        "\n",
        "##Resumen\n",
        "\n",
        "Aquí hemos visto:\n",
        "\n",
        "1. Qué es un valor atípico y cómo eliminarlo\n",
        "2. Cómo se pueden sesgar los datos\n",
        "3. Cómo mirar la difusión de datos\n",
        "4. Formas básicas de comparar variables, como calificaciones y tiempo de estudio.\n",
        "\n",
        "### Otras lecturas.\n",
        "\n",
        "Para obtener más información sobre los paquetes de Python que exploró en este cuaderno, consulte la siguiente documentación:\n",
        "\n",
        "* NumPy\n",
        "* Pandas\n",
        "* Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpC33KJC-HWd"
      },
      "source": [
        "# Verificación de conocimientos\n",
        "\n",
        "Responda las siguientes preguntas para comprobar su aprendizaje.\n",
        "\n",
        "1. **Tiene una matriz NumPy con la forma (2,20). ¿Qué te dice esto sobre los elementos de la matriz?**\n",
        "\n",
        "a) La matriz es bidimensional y consta de dos matrices cada una con 20 elementos.\n",
        "\n",
        "b) La matriz contiene 2 elementos, con los valores 2 y 20\n",
        "\n",
        "c) La matriz contiene 20 elementos, todos con el valor 2\n",
        "\n",
        "*Respuesta correcta:*\n",
        "\n",
        "*a) La matriz es bidimensional y consta de dos matrices cada una con 20 elementos.*\n",
        "\n",
        "2. **Tiene un DataFrame de Pandas llamado df_sales que contiene datos de ventas diarias. El DataFrame contiene las siguientes columnas: año, mes, día_de_month, sales_total. Desea encontrar el valor total de ventas promedio. ¿Qué código deberías usar?**\n",
        "\n",
        "a) df_sales ['sales_total']. avg ()\n",
        "\n",
        "b) df_sales ['sales_total']. mean ()\n",
        "\n",
        "c) mean (df_sales ['sales_total'])\n",
        "\n",
        "*Respuesta correcta:*\n",
        "\n",
        "*b) df_sales ['sales_total']. mean ()*\n",
        "\n",
        "\n",
        "3. **Tiene un DataFrame que contiene datos sobre las ventas diarias de helados. Utiliza el método corr para comparar las columnas avg_temp y units_sold, y obtiene un resultado de 0.97. ¿Qué indica este resultado?**\n",
        "\n",
        "a) En el día con el valor máximo de unidades vendidas, el valor avg_temp fue 0.97\n",
        "\n",
        "b) Los días con valores altos de avg_temp tienden a coincidir con días que tienen valores altos de unit_sold\n",
        "\n",
        "c) El valor de unit_sold es, en promedio, el 97% del valor avg_temp\n",
        "\n",
        "*Respuesta correcta:*\n",
        "\n",
        "*b) Los días con valores altos de avg_temp tienden a coincidir con días que tienen valores altos de unit_sold*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G7PJtsg_hd8"
      },
      "source": [
        "# Resumen\n",
        "\n",
        "En este módulo, aprendió a usar Python para explorar, visualizar y manipular datos. La exploración de datos es el núcleo de la ciencia de datos y es un elemento clave en el análisis de datos y el aprendizaje automático.\n",
        "\n",
        "El aprendizaje automático es un subconjunto de la ciencia de datos que se ocupa del modelado predictivo. En otras palabras, el aprendizaje automático utiliza datos para crear modelos predictivos, con el fin de predecir valores desconocidos. Puede utilizar el aprendizaje automático para predecir cuánta comida necesita pedir un supermercado o para identificar plantas en fotografías.\n",
        "\n",
        "El aprendizaje automático funciona identificando relaciones entre los valores de los datos que describen las características de algo, sus características , como la altura y el color de una planta, y el valor que queremos predecir, la etiqueta , como la especie de planta. Estas relaciones se integran en un modelo a través de un proceso de formación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z3QXIM6_rHf"
      },
      "source": [
        "# Desafío: analizar datos de vuelo\n",
        "\n",
        "Si estos ejercicios de este módulo le han inspirado a intentar explorar los datos por sí mismo, ¿por qué no aceptar el desafío de un conjunto de datos del mundo real que contenga registros de vuelos del Departamento de Transporte de EE. UU.? ¡Encontrarás el desafío en el cuaderno 01 - Flights Challenge.ipynb !\n",
        "\n",
        "> **Nota**.\n",
        "El tiempo para completar este desafío opcional no está incluido en el tiempo estimado para este módulo; ¡puede dedicarle tanto tiempo como desee!"
      ]
    }
  ]
}